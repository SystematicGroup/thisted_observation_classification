{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models for ObservationScheme Using PyCaret\n",
    "## Subsample: 10.000 of random concatenated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from pycaret.classification import *\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/NewData_ranCombination/Subsamples/Embeddings/LaBSE'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [f for f in listdir(data_dir) if isfile(join(data_dir, f))]\n",
    "all_files = [f[:-4] for f in all_files]\n",
    "label_files = sorted([f for f in all_files if ('label' in f)])       # alphabetically ordered\n",
    "filenames = sorted([f for f in all_files if (f not in label_files)]) # alphabetically ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.load(f'{data_dir}/{filenames[1]}.npy'))\n",
    "print('Shape of data:', data.shape)\n",
    "\n",
    "train = data.iloc[:-2000,:]\n",
    "test = data.iloc[-2000:,:]\n",
    "\n",
    "print('Train:', train.shape)\n",
    "print('Test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels = pd.DataFrame(np.load(f'{data_dir}/{label_files[1]}.npy'))\n",
    "train['obs_scheme'] = labels.iloc[:-2000,:]\n",
    "test['obs_scheme'] = labels.iloc[-2000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\", train.obs_scheme.nunique())\n",
    "print(\"Test: \", test.obs_scheme.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New test data: Standard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data_path = '/Subsamples/Embeddings'\n",
    "embeddings = ['LaBSE', 'tfidf','XLM-RoBERTa']\n",
    "subsamples = [10000,20000,50000,100000]\n",
    "embed_no = [768, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaBSE\n",
    "test = pd.DataFrame(np.load(f'{standard_data_path}/{embeddings[0]}/StandardData_cleaned_subsamples_{subsamples[0]}_{embeddings[0]}_embeddings_{embed_no[0]}.npy'))\n",
    "labels = pd.DataFrame(np.load(f'{standard_data_path}/{embeddings[0]}/labels_StandardData_cleaned_subsamples_{subsamples[0]}_{embeddings[0]}_embeddings_{embed_no[0]}.npy'))\n",
    "test['obs_scheme'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret Setup\n",
    "\n",
    "The setup() function of PyCaret initializes the environment and prepares the machine learning modeling data and deployment. There are two necessary parameters, a dataset, and the target variable. After executing the function, each feature's type is inferred, and several pre-processing tasks are performed on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = setup(\n",
    "    data = train,\n",
    "    test_data = test,\n",
    "    target = 'obs_scheme',\n",
    "    silent=True,\n",
    "    session_id = 1221)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = create_model('ridge', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = create_model('lda', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = create_model('svm', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model('lr', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(ridge, 'ridge_labse_12000_ranCombination')\n",
    "save_model(lda, 'lda_labse_12000_ranCombination')\n",
    "save_model(svm, 'svm_labse_12000_ranCombination')\n",
    "save_model(lr, 'LR_labse_12000_ranCombination')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply on unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_ridge = predict_model(ridge, test)\n",
    "ypred_lda = predict_model(lda, test)\n",
    "ypred_svm = predict_model(svm, test)\n",
    "ypred_lr = predict_model(lr, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Ridge:\", accuracy_score(ypred_ridge.obs_scheme, ypred_ridge.Label))\n",
    "print(\"LDA:\", accuracy_score(ypred_lda.obs_scheme, ypred_lda.Label))\n",
    "print(\"SVM:\", accuracy_score(ypred_svm.obs_scheme, ypred_svm.Label))\n",
    "print(\"LR:\", accuracy_score(ypred_lr.obs_scheme, ypred_lr.Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test['obs_scheme'], ypred_lr['Label'])\n",
    "cm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(\n",
    "    C=1.0,\n",
    "    class_weight=None,\n",
    "    dual=False,\n",
    "    fit_intercept = True,\n",
    "    intercept_scaling=1,\n",
    "    l1_ratio=None,\n",
    "    max_iter=1000,\n",
    "    multi_class='auto',\n",
    "    n_jobs=None,\n",
    "    penalty='l2',\n",
    "    random_state=1221,\n",
    "    solver='lbfgs',\n",
    "    tol=0.0001,\n",
    "    verbose=0,\n",
    "    warm_start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR.fit(train.iloc[:,:-1], train.obs_scheme)\n",
    "y_pred = LR.predict(test.iloc[:,:-1])\n",
    "print(\"Accuracy LR:\", accuracy_score(test.obs_scheme, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'LR_labse_12000_ranCombination_sklearn.sav'\n",
    "pickle.dump(LR, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = RidgeClassifier(\n",
    "    alpha=1.0,\n",
    "    class_weight=None,\n",
    "    copy_X=True,\n",
    "    fit_intercept = True,\n",
    "    max_iter=None,\n",
    "    normalize=False,\n",
    "    random_state=1221,\n",
    "    solver='auto',\n",
    "    tol=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge.fit(train.iloc[:,:-1], train.obs_scheme)\n",
    "y_pred = ridge.predict(test.iloc[:,:-1])\n",
    "print(\"Accuracy ridge:\", accuracy_score(test.obs_scheme, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'ridge_labse_12000_ranCombination_sklearn.sav'\n",
    "pickle.dump(ridge, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LinearDiscriminantAnalysis(\n",
    "    n_components=None,\n",
    "    priors=None,\n",
    "    shrinkage=None,\n",
    "    solver='svd',\n",
    "    store_covariance=False,\n",
    "    tol=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(train.iloc[:,:-1], train.obs_scheme)\n",
    "y_pred = lda.predict(test.iloc[:,:-1])\n",
    "print(\"Accuracy LDA:\", accuracy_score(test.obs_scheme, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'lda_labse_12000_ranCombination_sklearn.sav'\n",
    "pickle.dump(lda, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SGDClassifier(\n",
    "    alpha=0.0001,\n",
    "    average=False,\n",
    "    class_weight=None,\n",
    "    early_stopping=False,\n",
    "    epsilon=0.1,\n",
    "    eta0=0.001,\n",
    "    fit_intercept=True,\n",
    "    l1_ratio=0.15,\n",
    "    learning_rate='optimal',\n",
    "    loss='hinge',\n",
    "    max_iter=1000,\n",
    "    n_iter_no_change=5,\n",
    "    n_jobs=-1,\n",
    "    penalty='l2',\n",
    "    power_t=0.5,\n",
    "    random_state=1221,\n",
    "    shuffle=True,\n",
    "    tol=0.001,\n",
    "    validation_fraction=0.1,\n",
    "    verbose=0,\n",
    "    warm_start=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(train.iloc[:,:-1], train.obs_scheme)\n",
    "y_pred = svm.predict(test.iloc[:,:-1])\n",
    "print(\"Accuracy SVM:\", accuracy_score(test.obs_scheme, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'svm_labse_12000_ranCombination_sklearn.sav'\n",
    "pickle.dump(svm, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "520d1db8b5d7db4024068cda840687fc5229e2f4f4b5f1a68a03a2419364530e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('test2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
