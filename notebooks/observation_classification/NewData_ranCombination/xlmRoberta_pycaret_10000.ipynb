{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models for ObservationScheme Using PyCaret\n",
    "## Subsample: 10.000 of random concatenated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re,string\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "from pycaret.classification import *\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/NewData_ranCombination/Subsamples/Embeddings/xlmRoberta'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = [f for f in listdir(data_dir) if isfile(join(data_dir, f))]\n",
    "all_files = [f[:-4] for f in all_files]\n",
    "label_files = sorted([f for f in all_files if ('label' in f)])       # alphabetically ordered\n",
    "filenames = sorted([f for f in all_files if (f not in label_files)]) # alphabetically ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.load(f'{data_dir}/{filenames[1]}.npy'))\n",
    "print('Shape of data:', data.shape)\n",
    "\n",
    "train = data.iloc[:10000,:]\n",
    "val = data.iloc[10000:12000,:]\n",
    "test = data.iloc[-2000:,:]\n",
    "\n",
    "print('Train:', train.shape)\n",
    "print('Validation:', val.shape)\n",
    "print('Test:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels = pd.DataFrame(np.load(f'{data_dir}/{label_files[1]}.npy'))\n",
    "train['obs_scheme'] = labels.iloc[:10000,:]\n",
    "val['obs_scheme'] = labels.iloc[10000:12000,:]\n",
    "test['obs_scheme'] = labels.iloc[-2000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = train.obs_scheme.unique().tolist()\n",
    "val = val[val.obs_scheme.isin(train_list)]\n",
    "val.obs_scheme.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train\", train.obs_scheme.nunique())\n",
    "print(\"Val: \", val.obs_scheme.nunique())\n",
    "print(\"Test: \", test.obs_scheme.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyCaret Setup\n",
    "\n",
    "The setup() function of PyCaret initializes the environment and prepares the machine learning modeling data and deployment. There are two necessary parameters, a dataset, and the target variable. After executing the function, each feature's type is inferred, and several pre-processing tasks are performed on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = setup(\n",
    "    data = train,\n",
    "    test_data = val,\n",
    "    target = 'obs_scheme',\n",
    "    silent=True,\n",
    "    session_id = 1221)\n",
    "    # use_gpu = True\n",
    "    #feature_selection=True,      # a subset of features are selected using a combination of various permutation importance techniques\n",
    "    #remove_outliers = True       # outliers removed using PCA dimensionality reduction   \n",
    "    #ignore_low_variance = True, \n",
    "    #remove_multicollinearity = True,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_models(\n",
    "    sort='acc',\n",
    "    cross_validation = False, #, fold=3)\n",
    "    exclude= ['gbc','qda', 'lightgbm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = create_model('ridge', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = create_model('lda', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = create_model('svm', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = create_model('lr', cross_validation = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ridge = tune_model(ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lda = tune_model(lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_svm = tune_model(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lr = tune_model(lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply on unseen test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_ridge = predict_model(t_ridge, test)\n",
    "ypred_lda = predict_model(t_lda, test)\n",
    "ypred_svm = predict_model(t_svm, test)\n",
    "ypred_lr = predict_model(t_lr, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ypred.to_csv(f'{processed_data_dir}/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Ridge:\", accuracy_score(ypred_ridge.obs_scheme, ypred_ridge.Label))\n",
    "print(\"LDA:\", accuracy_score(ypred_lda.obs_scheme, ypred_lda.Label))\n",
    "print(\"SVM:\", accuracy_score(ypred_svm.obs_scheme, ypred_svm.Label))\n",
    "print(\"LR:\", accuracy_score(ypred_lr.obs_scheme, ypred_lr.Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = metrics.confusion_matrix(test['obs_scheme'], ypred_lr['Label'])\n",
    "cm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure(figsize = (20,10))\n",
    "sns.heatmap(pd.DataFrame(cm), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New test data: Standard data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_data_path = '/Testborger/Subsamples/Embeddings'\n",
    "embeddings = ['LaBSE', 'tfidf','XLM-RoBERTa']\n",
    "subsamples = [10000,20000,50000,100000]\n",
    "embed_no = [768, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LaBSE\n",
    "test = pd.DataFrame(np.load(f'{standard_data_path}/{embeddings[2]}/StandardData_cleaned_subsamples_{subsamples[0]}_roberta-large_embeddings_{embed_no[1]}.npy'))\n",
    "labels = pd.DataFrame(np.load(f'{standard_data_path}/{embeddings[2]}/labels_StandardData_cleaned_subsamples_{subsamples[0]}_roberta-large_embeddings_{embed_no[1]}.npy'))\n",
    "test['obs_scheme'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_ridge = predict_model(t_ridge, test)\n",
    "ypred_lda = predict_model(t_lda, test)\n",
    "ypred_svm = predict_model(t_svm, test)\n",
    "ypred_lr = predict_model(t_lr, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy for standard data as test set:\")\n",
    "print(\"Ridge:\", accuracy_score(ypred_ridge.obs_scheme, ypred_ridge.Label))\n",
    "print(\"LDA:\", accuracy_score(ypred_lda.obs_scheme, ypred_lda.Label))\n",
    "print(\"SVM:\", accuracy_score(ypred_svm.obs_scheme, ypred_svm.Label))\n",
    "print(\"LR:\", accuracy_score(ypred_lr.obs_scheme, ypred_lr.Label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "520d1db8b5d7db4024068cda840687fc5229e2f4f4b5f1a68a03a2419364530e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('test2': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
